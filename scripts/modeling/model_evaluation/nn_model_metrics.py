import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, roc_auc_score


# TODO: troubleshoot roc_auc_score
def evaluate(predictions, targets, flat_shape, threshold_value=0.515):
    """
    Description: Evaluate the model using standard metrics:
      - Accuracy: Overall correctness.
      - Precision: Ratio of true positive predictions to total positive predictions.
      - Recall: Ratio of true positive predictions to actual positives.
      - F1 Score: Harmonic mean of precision and recall.
    Returns dictionary of all four metrics calculated

    Parameters:
        predictions: torch.Tensor
            Batch of predictions generated by model, have shape [batch_size, 37, 34] for our use case
        targets: torch.Tensor
            Ground truth values, have shape [batch_size, 37, 34] for our use case
        flat_shape: int
            Size of entire batch when flattened
        threshold_value: float
            Default: 0.515
            Threshold for class separation
    Returns:
        metrics: Dict
            Dictionary containing evaluation metrics.
    """
    # flatten arrays
    # detach to ensure gradients of tensors are not affected, shift computation to cpu, convert to numpy
    predictions_flat = predictions.detach().cpu().numpy().reshape(flat_shape)
    targets_flat = targets.detach().cpu().numpy().reshape(flat_shape)

    # threshold predictions to give 1 and 0
    # all prediction values > threshold_value become class 1, all others become class 0
    thresholded_predictions_flat = (predictions_flat > threshold_value).astype(int)

    # compute metrics using scikit-learn
    metrics = {
        "accuracy": accuracy_score(targets_flat.astype(int), thresholded_predictions_flat),
        "precision": precision_score(targets_flat.astype(int), thresholded_predictions_flat),
        "recall": recall_score(targets_flat.astype(int), thresholded_predictions_flat),
        "f1": f1_score(targets_flat.astype(int), thresholded_predictions_flat)
    }
    return metrics


def evaluate_individuals(predictions, targets, flat_shape, threshold_value=0.515):
    """
    Description: Evaluate the model using standard metrics:
      - Accuracy: Overall correctness.
      - Precision: Ratio of true positive predictions to total positive predictions.
      - Recall: Ratio of true positive predictions to actual positives.
      - F1 Score: Harmonic mean of precision and recall.
    Returns all four metrics individually

    Parameters:
        predictions: torch.Tensor
            Batch of predictions generated by model, have shape [batch_size, 37, 34] for our use case
        targets: torch.Tensor
            Ground truth values, have shape [batch_size, 37, 34] for our use case
        flat_shape: int
            Size of entire batch when flattened
        threshold_value: float
            Default: 0.515
            Threshold for class separation

    Returns:
        float, float, float, float
            accuracy, precision, recall, and f1_score values for batch
    """
    # flatten arrays
    # detach to ensure gradients of tensors are not affected, shift computation to cpu, convert to numpy
    predictions_flat = predictions.detach().cpu().numpy().reshape(flat_shape)
    targets_flat = targets.detach().cpu().numpy().reshape(flat_shape)

    # threshold predictions to give 1 and 0
    # all prediction values > threshold_value become class 1, all others become class 0
    thresholded_predictions_flat = (predictions_flat > threshold_value).astype(int)
    if targets_flat.sum() == 0:
        print('No fire areas present in batch')
    if thresholded_predictions_flat.sum() == 0:
        print(f"No fire areas predicted in batch using threshold {threshold_value}")

    # compute metrics using scikit-learn
    accuracy = accuracy_score(targets_flat, thresholded_predictions_flat)
    precision = precision_score(targets_flat.astype(int), thresholded_predictions_flat)
    recall = recall_score(targets_flat.astype(int), thresholded_predictions_flat)
    f1 = f1_score(targets_flat.astype(int), thresholded_predictions_flat)

    return accuracy, precision, recall, f1
